# ğŸ¤– LLM Provider Configuration
# Choose your default AI provider: google, ollama, openai
DEFAULT_PROVIDER=google

# ğŸ’ Google Generative AI (Gemini)
# Get your key at: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# ğŸ§  OpenAI Configuration
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# ğŸ  Ollama Configuration (Local AI)
# If using Docker, use: http://host.docker.internal:11434
OLLAMA_BASE_URL=http://localhost:11434

# âš™ï¸ Model Parameters
# These are default values; they can be tuned for different models.
LLM_MODEL=gemini-2.0-flash-exp
LLM_TEMPERATURE=0
LLM_TOP_P=0.95
LLM_TOP_K=64
LLM_MAX_OUTPUT_TOKENS=8192

# ğŸ‘ï¸ OCR Configuration
# Windows: C:\Program Files\Tesseract-OCR\tesseract.exe
# Linux: /usr/bin/tesseract
# macOS: /usr/local/bin/tesseract
TESSERACT_CMD=

# ğŸ’¾ Database & Application
DATABASE_PATH=invoices.db
APP_TITLE=InvoiceIQ
MAX_PAGES_PER_PDF=10

# ğŸ“ Logging
LOG_LEVEL=INFO
LOG_FILE=app.log
